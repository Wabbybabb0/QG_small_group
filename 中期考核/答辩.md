## 一.概念理解

每个智能体都有一个以真实数值代表的观点，然后他会通过平均所有跟他距离相差不少于一的智能体来改变自身的数值

我觉得比较关键的还是这个(1)的公式，它明确了一个智能体更新的过程，然后右边的`opinion_update`也是在复现过程中贯穿所有图示的一个函数

一个智能体同时也是他自己的neighbor

在一个有限的时间里进行收敛，总会经历一段时间：一组智能体收敛到一个值，然后他们不会再与这个值之外的任何智能体建立联系。那么这一组智能体就会计算成相同的值。

clusters:智能体状态收敛成的一个极限值被视为clusters

## 二.模型复现及图示展示

### 1.Fig5

#### 要求

1.在[0,2.5]范围平均分布251个智能体，在[2.5,3]范围平均分布500个智能体

2.结合**Theorem2**，当两个clusters`A` `B`在以下情况才能保证平衡是稳定的：

* `W_A` = `W_B`

* `W_A`!=`W_B`   且  |`x_A `-` x_B`| > 1 + min(`W_A`,`W_B`)/max(`W_A`,`W_B`)

  * 满足第二个情况同时也会满足

    max{|`m`-`x_A`|, |`m`-`x_B`|} > 1

    其中：`m` =( `W_A`\*`x_A` + `W_B`\*`x_B`)/(`W_A`+`W_B`) 是这组智能体的中心位置

    那么就是说只要最终收敛的值距离其中一个cluster的距离大于1，那么这组智能体就能保持稳定平衡

#### ①test01

首先是按要求创建数据集

* 用到了`np.linspace`和`np.concatenate`把所有数据放在`data`里

#### ②done

改成了二维数组，然后画点连线



### 2.Fig3

就是没跑好，数据量太大了可能是



### 3.Fig4

#### 要求：

最初的两组智能体之间没有联系，但是在他们之间有一些智能体跟他们分别有联系，于是这两组智能体之间的距离最终小于1，然后就建立了联系，最终收敛为一个值

#### ①test01

数据集为：300个[0,1]、50个[1,3]、300个[3,4]

#### ②test02

数据集为：300个[0,1]、150个[1,3]、300个[3,4]



#### 4.Fig2

#### 要求：

一个个数为5000L平均分布在[0,L]的数据集，显示不同L下最后收敛的数值距离L/2的大小

#### 思路：

刚开始觉得它难是不知道怎么找收敛点，然后再翻看论文的时候，看到`Theorem1`中提到了可以根据L初步得出clusters的个数为[L]+1，于是就有了

```python
m = X.shape[0]
index_num = L + 1
for i in range(index_num):
    index = (int)(m/L)*i - 1
    L.all.append(X[index])
```

`L_all`是存放所有clusters的值，可能会重复

`L_result`是把重复的clusters的值去掉

#### 不足：

就是，没能写出来让他在一副图上画出多个L的一个整合的函数，只能让他一组一组地去分析